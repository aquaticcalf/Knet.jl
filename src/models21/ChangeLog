2021-02-24  dyuret  <dyuret@login03.kuacc.ku.edu.tr>

	* tensorflow-eval:
	https://medium.com/analytics-vidhya/how-to-train-a-neural-network-classifier-on-imagenet-using-tensorflow-2-ede0ea3a35ff
	https://stackoverflow.com/questions/37340129/tensorflow-training-on-my-own-image

	* torchvision-eval:
	official eval script:
	  https://github.com/pytorch/examples/tree/master/imagenet
	Normalization for all torchvision models:
	transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])),
	eval command:
	  python main.py --pretrained -e -a mobilenet_v2 /datasets/ImageNet/ILSVRC/Data/CLS-LOC
	  mobilenet_v2: Acc@1 71.850 Acc@5 90.334
	  resnet18: Acc@1 69.644 Acc@5 88.982

2021-02-13  Deniz Yuret  <dyuret@WS001>

	* tf.ZeroPadding2D:

	function zeropad1(x)            # 16ms
	    w,h,c,n = size(x)
	    f = oftype(x, reshape([0 0 0 1], 2, 2, 1, 1))
	    x = reshape(x, (w, h, 1, :))
	    x = conv(f, x; padding = 1)
	    x = reshape(x, (size(x,1), size(x,2), c, n))
	end

	function zeropad2(x)            # 5ms
	    w,h,c,n = size(x)
	    x = cat(x, fill!(similar(x, (1,h,c,n)), 0); dims=1)
	    x = cat(x, fill!(similar(x, (w+1,1,c,n)), 0); dims=2)
	end

	_f = nothing

	function zeropad3(x)            # 1ms
	    global _f
	    w,h,c,n = size(x)
	    if typeof(_f) != typeof(x) || size(_f) != (2,2,1,c)
	        _f = oftype(x, zeros(Float32, 2, 2, 1, c))
	        _f[2,2,1,:] .= 1
	    end
	    x = conv(_f, x; padding = 1, groups = c)
	end

	_x = nothing

	function zeropad4(x) # 3.4ms
	    global _x
	    w,h,c,n = size(x)
	    if typeof(_x) != typeof(x) || size(_x) != (w+1,h+1,c,n)
	        _x = fill!(similar(x, (w+1,h+1,c,n)), 0)
	    end
	    _x[1:w,1:h,:,:] .= x
	    _x
	end

	conv(w, zeropad3(x); groups=128, stride=2) # min=0.2 med=1.4 mean=6.4ms
	conv(w, x; groups=128, stride=2, padding=2)[2:end,2:end,:,:] # min=0.02 med=2.1 mean=1.9ms

2021-02-12  Deniz Yuret  <dyuret@WS001>

	* tf.keras.applications.mobilenet.preprocess_input:
	Takes a (1,224,224,3) image with pixel values in 0:255 Float32.
	Returns a (1,224,224,3) image with pixel values in -1:1 Float32.
	Calls tf.keras.applications.imagenet_utils.preprocess_input(mode='tf')
	tf: will scale pixels between -1 and 1, sample-wise. (means per-image)

2021-02-10  Deniz Yuret  <dyuret@WS001>

	* keras:
	# channels_last (default) corresponds to inputs with shape (batch_size, height, width, channels) while
	# channels_first corresponds to inputs with shape (batch_size, channels, height, width)
	knet default is (w,h,c,n), reverse of channels_first, permutedims(3,2,4,1) of channels last

2021-02-05  Deniz Yuret  <dyuret@WS001>

	* conv: both tf and pytorch seems to perform cross-correlation by default:
	https://www.tensorflow.org/api_docs/python/tf/nn/convolution
	https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html

	* shape: tensorflow vs pytorch weights seem transposed:
	>>> p50 = torchvision.models.resnet50(pretrained=True)
	>>> r50=tf.keras.applications.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)
	>>> pw = p50.conv1.weight.detach().numpy()
	>>> tw = t50.weights[0]
	>>> tw.shape
	(7, 7, 3, 64)
	>>> pw.shape
	(64, 3, 7, 7)

	* images: Julia.Images vs python.PIL.Image
        CUDNN_TENSOR_NCHW,        # 0, /* row major (wStride = 1, hStride = w) */
        CUDNN_TENSOR_NHWC,        # 1, /* feature maps interleaved ( cStride = 1 )*/
	cudnn:nchw => julia:whcn
	cudnn:nhwc => julia:cwhn
	i1=python-image, j1=julia-image
	size(j1) => h,w
	channelview(j1) => c,h,w
	reinterpretc(N0f8,j1) => c,h,w
	np.asarray(i1).shape => h,w,c (python array)
	np.array(i1) => h,w,c Array
	transforms.ToTensor()(i1).numpy() => c,h,w (same as channelview)
